{"cells":[{"metadata":{},"cell_type":"markdown","source":"# CNN 2D Basic Solution Powered by fast.ai\n\nThis kernel explains basic solution that I've used in the last competition and many of top competitors also.\nIt's CNN, even ImageNet pretrained model works fine with audio 2D image like data.\n\nWill show:\n\n- Converting audio to 2D image like array, so that we can simply exploit strong CNN classifier.\n- fast.ai to build fast and strong multi-label classifier model. Unlike normal use, we need to train from scratch to comply competition rule. (Though if we use ImageNet pretrained model, it converges super fast...)\n- With simple codes."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\nimport IPython\nimport IPython.display\nimport PIL\nimport time\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## File/folder definitions\n\n- `df` will handle training data.\n- `test_df` will handle test data."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"start_time = time.time()\n\nDATA = Path('../input')\nCSV_TRN_CURATED = DATA/'train_curated.csv'\nCSV_TRN_NOISY = DATA/'train_noisy.csv'\nCSV_SUBMISSION = DATA/'sample_submission.csv'\nTRN_CURATED = DATA/'train_curated'\nTRN_NOISY = DATA/'train_noisy'\nTEST = DATA/'test'\n\nWORK = Path('work')\nIMG_TRN_CURATED = WORK/'image/trn_curated'\nIMG_TRN_NOISY = WORK/'image/trn_curated'\nIMG_TEST = WORK/'image/test'\nfor folder in [WORK, IMG_TRN_CURATED, IMG_TRN_NOISY, IMG_TEST]: \n    Path(folder).mkdir(exist_ok=True, parents=True)\n\ndf = pd.read_csv(CSV_TRN_CURATED)\ntest_df = pd.read_csv(CSV_SUBMISSION)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false},"cell_type":"markdown","source":"## EasyDict to handle configurations easily\n\nThanks to https://github.com/makinacorpus/easydict"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Special thanks to https://github.com/makinacorpus/easydict/blob/master/easydict/__init__.py\nclass EasyDict(dict):\n    \"\"\"\n    Get attributes\n    >>> d = EasyDict({'foo':3})\n    >>> d['foo']\n    3\n    >>> d.foo\n    3\n    >>> d.bar\n    Traceback (most recent call last):\n    ...\n    AttributeError: 'EasyDict' object has no attribute 'bar'\n    Works recursively\n    >>> d = EasyDict({'foo':3, 'bar':{'x':1, 'y':2}})\n    >>> isinstance(d.bar, dict)\n    True\n    >>> d.bar.x\n    1\n    Bullet-proof\n    >>> EasyDict({})\n    {}\n    >>> EasyDict(d={})\n    {}\n    >>> EasyDict(None)\n    {}\n    >>> d = {'a': 1}\n    >>> EasyDict(**d)\n    {'a': 1}\n    Set attributes\n    >>> d = EasyDict()\n    >>> d.foo = 3\n    >>> d.foo\n    3\n    >>> d.bar = {'prop': 'value'}\n    >>> d.bar.prop\n    'value'\n    >>> d\n    {'foo': 3, 'bar': {'prop': 'value'}}\n    >>> d.bar.prop = 'newer'\n    >>> d.bar.prop\n    'newer'\n    Values extraction\n    >>> d = EasyDict({'foo':0, 'bar':[{'x':1, 'y':2}, {'x':3, 'y':4}]})\n    >>> isinstance(d.bar, list)\n    True\n    >>> from operator import attrgetter\n    >>> map(attrgetter('x'), d.bar)\n    [1, 3]\n    >>> map(attrgetter('y'), d.bar)\n    [2, 4]\n    >>> d = EasyDict()\n    >>> d.keys()\n    []\n    >>> d = EasyDict(foo=3, bar=dict(x=1, y=2))\n    >>> d.foo\n    3\n    >>> d.bar.x\n    1\n    Still like a dict though\n    >>> o = EasyDict({'clean':True})\n    >>> o.items()\n    [('clean', True)]\n    And like a class\n    >>> class Flower(EasyDict):\n    ...     power = 1\n    ...\n    >>> f = Flower()\n    >>> f.power\n    1\n    >>> f = Flower({'height': 12})\n    >>> f.height\n    12\n    >>> f['power']\n    1\n    >>> sorted(f.keys())\n    ['height', 'power']\n    update and pop items\n    >>> d = EasyDict(a=1, b='2')\n    >>> e = EasyDict(c=3.0, a=9.0)\n    >>> d.update(e)\n    >>> d.c\n    3.0\n    >>> d['c']\n    3.0\n    >>> d.get('c')\n    3.0\n    >>> d.update(a=4, b=4)\n    >>> d.b\n    4\n    >>> d.pop('a')\n    4\n    >>> d.a\n    Traceback (most recent call last):\n    ...\n    AttributeError: 'EasyDict' object has no attribute 'a'\n    \"\"\"\n    def __init__(self, d=None, **kwargs):\n        if d is None:\n            d = {}\n        if kwargs:\n            d.update(**kwargs)\n        for k, v in d.items():\n            setattr(self, k, v)\n        # Class attributes\n        for k in self.__class__.__dict__.keys():\n            if not (k.startswith('__') and k.endswith('__')) and not k in ('update', 'pop'):\n                setattr(self, k, getattr(self, k))\n\n    def __setattr__(self, name, value):\n        if isinstance(value, (list, tuple)):\n            value = [self.__class__(x)\n                     if isinstance(x, dict) else x for x in value]\n        elif isinstance(value, dict) and not isinstance(value, self.__class__):\n            value = self.__class__(value)\n        super(EasyDict, self).__setattr__(name, value)\n        super(EasyDict, self).__setitem__(name, value)\n\n    __setitem__ = __setattr__\n\n    def update(self, e=None, **f):\n        d = e or dict()\n        d.update(f)\n        for k in d:\n            setattr(self, k, d[k])\n\n    def pop(self, k, d=None):\n        delattr(self, k)\n        return super(EasyDict, self).pop(k, d)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Audio conversion to 2D\n\nAlmost copyed from my repository: https://github.com/daisukelab/ml-sound-classifier\n- Handle sampling rate 44.1kHz as is, no information loss.\n- Size of each file will be 128 x L, L is audio seconds x 128; `[128, 256]`  if sound is 2s long.\n- Convert to Mel-spectrogram, not MFCC. We are handling general sound rather than human voice. https://en.wikipedia.org/wiki/Spectrogram"},{"metadata":{"trusted":true},"cell_type":"code","source":"import librosa\nimport librosa.display\n\ndef read_audio(conf, pathname, trim_long_data):\n    y, sr = librosa.load(pathname, sr=conf.sampling_rate)\n    # trim silence\n    if 0 < len(y): # workaround: 0 length causes error\n        y, _ = librosa.effects.trim(y) # trim, top_db=default(60)\n    # make it unified length to conf.samples\n    if len(y) > conf.samples: # long enough\n        if trim_long_data:\n            y = y[0:0+conf.samples]\n    else: # pad blank\n        padding = conf.samples - len(y)    # add padding at both ends\n        offset = padding // 2\n        y = np.pad(y, (offset, conf.samples - len(y) - offset), 'constant')\n    return y\n\ndef audio_to_melspectrogram(conf, audio):\n    spectrogram = librosa.feature.melspectrogram(audio, \n                                                 sr=conf.sampling_rate,\n                                                 n_mels=conf.n_mels,\n                                                 hop_length=conf.hop_length,\n                                                 n_fft=conf.n_fft,\n                                                 fmin=conf.fmin,\n                                                 fmax=conf.fmax)\n    spectrogram = librosa.power_to_db(spectrogram)\n    spectrogram = spectrogram.astype(np.float32)\n    return spectrogram\n\ndef show_melspectrogram(conf, mels, title='Log-frequency power spectrogram'):\n    librosa.display.specshow(mels, x_axis='time', y_axis='mel', \n                             sr=conf.sampling_rate, hop_length=conf.hop_length,\n                            fmin=conf.fmin, fmax=conf.fmax)\n    plt.colorbar(format='%+2.0f dB')\n    plt.title(title)\n    plt.show()\n\ndef read_as_melspectrogram(conf, pathname, trim_long_data, debug_display=False):\n    x = read_audio(conf, pathname, trim_long_data)\n    mels = audio_to_melspectrogram(conf, x)\n    if debug_display:\n        IPython.display.display(IPython.display.Audio(x, rate=conf.sampling_rate))\n        show_melspectrogram(conf, mels)\n    return mels\n\n\nconf = EasyDict()\nconf.sampling_rate = 44100\nconf.duration = 2\nconf.hop_length = 347 # to make time steps 128\nconf.fmin = 20\nconf.fmax = conf.sampling_rate // 2\nconf.n_mels = 128\nconf.n_fft = conf.n_mels * 20\n\nconf.samples = conf.sampling_rate * conf.duration\n\n# example\nx = read_as_melspectrogram(conf, TRN_CURATED/'0006ae4e.wav', trim_long_data=False, debug_display=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Making 2D mel-spectrogram data as 2D 3ch images\n\nSo that normal CNN image classifier can handle.\nI wanted to put them into files, but kernel has restriction to keep files less than 500.\nWe need to keep the data on memory.\n\nOf course this has positive effect, training gets faster."},{"metadata":{"trusted":true},"cell_type":"code","source":"def mono_to_color(X, mean=None, std=None, norm_max=None, norm_min=None, eps=1e-6):\n    # Stack X as [X,X,X]\n    X = np.stack([X, X, X], axis=-1)\n\n    # Standardize\n    mean = mean or X.mean()\n    std = std or X.std()\n    Xstd = (X - mean) / (std + eps)\n    _min, _max = Xstd.min(), Xstd.max()\n    norm_max = norm_max or _max\n    norm_min = norm_min or _min\n    if (_max - _min) > eps:\n        # Scale to [0, 255]\n        V = Xstd\n        V[V < norm_min] = norm_min\n        V[V > norm_max] = norm_max\n        V = 255 * (V - norm_min) / (norm_max - norm_min)\n        V = V.astype(np.uint8)\n    else:\n        # Just zero\n        V = np.zeros_like(Xstd, dtype=np.uint8)\n    return V\n\ndef convert_wav_to_image(df, source, img_dest):\n    X = []\n    for i, row in tqdm_notebook(df.iterrows()):\n        x = read_as_melspectrogram(conf, source/str(row.fname), trim_long_data=False)\n        x_color = mono_to_color(x)\n        X.append(x_color)\n    return df, X\n\ndf2, X_train = convert_wav_to_image(df, source=TRN_CURATED, img_dest=IMG_TRN_CURATED)\ntest_df2, X_test = convert_wav_to_image(test_df, source=TEST, img_dest=IMG_TEST)\nprint(f\"Finished data conversion at {(time.time()-start_time)/3600} hours\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Custom `open_image` for fast.ai library to load data from memory\n\n- Important note: Random cropping 1 sec, this is working like augmentation."},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai import *\nfrom fastai.vision import *\nfrom fastai.vision.data import *\nimport random\n\nCUR_X_FILES, CUR_X = list(df.fname.values), X_train\n\ndef open_fat2019_image(fn, convert_mode, after_open)->Image:\n    # open\n    idx = CUR_X_FILES.index(fn.split('/')[-1])\n    x = PIL.Image.fromarray(CUR_X[idx])\n    # crop\n    time_dim, base_dim = x.size\n    crop_x = random.randint(0, time_dim - base_dim)\n    x = x.crop([crop_x, 0, crop_x+base_dim, base_dim])    \n    # standardize\n    return Image(pil2tensor(x, np.float32).div_(255))\n\nvision.data.open_image = open_fat2019_image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Follow multi-label classification\n\n- Almost following fast.ai course: https://nbviewer.jupyter.org/github/fastai/course-v3/blob/master/nbs/dl1/lesson3-planet.ipynb\n- But `pretrained=False`"},{"metadata":{"trusted":true},"cell_type":"code","source":"tfms = get_transforms(do_flip=True, max_rotate=0, max_lighting=0.1, max_zoom=0, max_warp=0.)\nsrc = (ImageList.from_csv(WORK/'image', Path('../../')/CSV_TRN_CURATED, folder='trn_curated')\n       .split_by_rand_pct(0.2)\n       .label_from_df(label_delim=',')\n)\ndata = (src.transform(tfms, size=128)\n        .databunch(bs=64).normalize(imagenet_stats)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_score = partial(fbeta, thresh=0.2)\nlearn = cnn_learner(data, models.resnet18, pretrained=False, metrics=[f_score])\nlearn.unfreeze()\n\nlearn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(5, slice(1e-6, 1e-1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(100, slice(1e-6, 1e-2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('fat2019_fastai_cnn2d_stage-2')\nlearn.export()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test prediction and making submission file simple\n- Switch to test data.\n- Overwrite results to sample submission; simple way to prepare submission file."},{"metadata":{"trusted":true},"cell_type":"code","source":"CUR_X_FILES, CUR_X = list(test_df.fname.values), X_test\n\ntest = ImageList.from_csv(WORK/'image', Path('../..')/CSV_SUBMISSION, folder='test')\nlearn = load_learner(WORK/'image', test=test)\npreds, _ = learn.get_preds(ds_type=DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df[learn.data.classes] = preds\ntest_df.to_csv('submission.csv', index=False)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Kernel run time = {(time.time()-start_time)/3600} hours\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CUR_X_FILES, CUR_X = list(df.fname.values), X_train\nlearn = cnn_learner(data, models.resnet18, pretrained=False, metrics=[f_score])\nlearn.load('fat2019_fastai_cnn2d_stage-2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to https://nbviewer.jupyter.org/github/fastai/course-v3/blob/master/nbs/dl1/lesson6-pets-more.ipynb\nfrom fastai.callbacks.hooks import *\n\ndef visualize_cnn_by_cam(learn, data_index):\n    x, _y = learn.data.valid_ds[data_index]\n    y = _y.data\n    if not isinstance(y, (list, np.ndarray)): # single label -> one hot encoding\n        y = np.eye(learn.data.valid_ds.c)[y]\n\n    m = learn.model.eval()\n    xb,_ = learn.data.one_item(x)\n    xb_im = Image(learn.data.denorm(xb)[0])\n    xb = xb.cuda()\n\n    def hooked_backward(cat):\n        with hook_output(m[0]) as hook_a: \n            with hook_output(m[0], grad=True) as hook_g:\n                preds = m(xb)\n                preds[0,int(cat)].backward()\n        return hook_a,hook_g\n    def show_heatmap(img, hm, label):\n        _,axs = plt.subplots(1, 2)\n        axs[0].set_title(label)\n        img.show(axs[0])\n        axs[1].set_title(f'CAM of {label}')\n        img.show(axs[1])\n        axs[1].imshow(hm, alpha=0.6, extent=(0,img.shape[0],img.shape[0],0),\n                      interpolation='bilinear', cmap='magma');\n        plt.show()\n\n    for y_i in np.where(y > 0)[0]:\n        hook_a,hook_g = hooked_backward(cat=y_i)\n        acts = hook_a.stored[0].cpu()\n        grad = hook_g.stored[0][0].cpu()\n        grad_chan = grad.mean(1).mean(1)\n        mult = (acts*grad_chan[...,None,None]).mean(0)\n        show_heatmap(img=xb_im, hm=mult, label=str(learn.data.valid_ds.y[data_index]))\n\nfor idx in range(10):\n    visualize_cnn_by_cam(learn, idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}